{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "处理完成！原始文件: ../dataset/pretrain_4096.jsonl\n",
      "新文件已保存为: ../dataset/pretrain_4096_new.jsonl\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# 输入和输出文件路径\n",
    "input_file = '../dataset/pretrain_4096.jsonl'\n",
    "output_file = '../dataset/pretrain_4096_new.jsonl'\n",
    "\n",
    "# # 确保输入文件路径是相对于当前工作目录的\n",
    "input_path = os.path.join(os.getcwd(), input_file)\n",
    "output_path = os.path.join(os.getcwd(), output_file)\n",
    "\n",
    "# 处理文件\n",
    "with open(input_path, 'r', encoding='utf-8') as f_in, open(output_path, 'w', encoding='utf-8') as f_out:\n",
    "    for line in f_in:\n",
    "        if line.strip():  # 跳过空行\n",
    "            try:\n",
    "                # 解析JSON\n",
    "                data = json.loads(line.strip())\n",
    "                \n",
    "                # 创建新的字典，只包含text字段\n",
    "                new_data = {}\n",
    "                \n",
    "                # 如果存在\"content\"键，将其重命名为\"text\"\n",
    "                if \"content\" in data:\n",
    "                    new_data[\"text\"] = data[\"content\"]\n",
    "                \n",
    "                # 写入转换后的JSON\n",
    "                f_out.write(json.dumps(new_data, ensure_ascii=False) + '\\n')\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"警告：无法解析行: {line}\")\n",
    "                # 对于无法解析的行，保持原样写入\n",
    "                f_out.write(line)\n",
    "\n",
    "print(f\"处理完成！原始文件: {input_file}\")\n",
    "print(f\"新文件已保存为: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "找到 15 个JSONL文件，开始合并...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理文件进度:   7%|▋         | 1/15 [00:02<00:40,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - 已处理 34 行\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理文件进度:  13%|█▎        | 2/15 [00:11<01:24,  6.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - 已处理 275596 行\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理文件进度:  20%|██        | 3/15 [00:29<02:21, 11.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - 已处理 655747 行\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理文件进度:  27%|██▋       | 4/15 [00:35<01:43,  9.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - 已处理 396209 行\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理文件进度:  33%|███▎      | 5/15 [01:47<05:17, 31.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - 已处理 1574271 行\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理文件进度:  40%|████      | 6/15 [01:47<03:09, 21.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - 已处理 15 行\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理文件进度:  47%|████▋     | 7/15 [03:50<07:14, 54.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - 已处理 2228317 行\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理文件进度:  53%|█████▎    | 8/15 [04:07<04:58, 42.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - 已处理 631744 行\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理文件进度:  60%|██████    | 9/15 [04:25<03:29, 34.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - 已处理 389483 行\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理文件进度:  67%|██████▋   | 10/15 [05:03<02:59, 35.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - 已处理 337993 行\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理文件进度:  73%|███████▎  | 11/15 [05:16<01:54, 28.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - 已处理 770086 行\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理文件进度:  80%|████████  | 12/15 [05:50<01:31, 30.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - 已处理 836075 行\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理文件进度:  87%|████████▋ | 13/15 [06:54<01:21, 40.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - 已处理 4060616 行\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理文件进度:  93%|█████████▎| 14/15 [07:03<00:30, 30.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - 已处理 254547 行\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理文件进度: 100%|██████████| 15/15 [07:21<00:00, 29.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - 已处理 1043224 行\n",
      "\n",
      "合并完成！\n",
      "总共处理了 15 个文件\n",
      "合并了 13453957 行数据\n",
      "跳过了 0 行无效数据\n",
      "合并后的文件已保存为: merged_data.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 设置输入和输出路径\n",
    "downloads_dir = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(\"__file__\"))), \"downloads\")\n",
    "output_file = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(\"__file__\"))), \"dataset\", \"merged_data.jsonl\")\n",
    "\n",
    "# 确保输出目录存在\n",
    "os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "\n",
    "# 获取所有的jsonl文件\n",
    "jsonl_files = glob.glob(os.path.join(downloads_dir, \"*.jsonl\"))\n",
    "\n",
    "print(f\"找到 {len(jsonl_files)} 个JSONL文件，开始合并...\")\n",
    "\n",
    "# 统计信息\n",
    "total_lines = 0\n",
    "processed_files = 0\n",
    "error_lines = 0\n",
    "\n",
    "# 合并文件\n",
    "with open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "    # 使用tqdm包装文件列表，显示文件处理进度\n",
    "    for file_path in tqdm(jsonl_files, desc=\"处理文件进度\"):\n",
    "        file_name = os.path.basename(file_path)\n",
    "        \n",
    "        try:\n",
    "            # 首先获取文件行数，用于tqdm进度条\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                line_count = sum(1 for _ in f)\n",
    "            \n",
    "            with open(file_path, 'r', encoding='utf-8') as infile:\n",
    "                file_lines = 0\n",
    "                # 使用tqdm显示每个文件内部的处理进度\n",
    "                for line in tqdm(infile, total=line_count, desc=f\"处理 {file_name}\", leave=False):\n",
    "                    try:\n",
    "                        # 验证JSON格式是否正确\n",
    "                        json.loads(line.strip())\n",
    "                        outfile.write(line)\n",
    "                        file_lines += 1\n",
    "                    except json.JSONDecodeError:\n",
    "                        error_lines += 1\n",
    "                        continue\n",
    "                \n",
    "                total_lines += file_lines\n",
    "                processed_files += 1\n",
    "                print(f\"  - 已处理 {file_lines} 行\")\n",
    "        except UnicodeDecodeError:\n",
    "            # 尝试使用GBK编码\n",
    "            try:\n",
    "                # 首先获取文件行数，用于tqdm进度条\n",
    "                with open(file_path, 'r', encoding='gbk') as f:\n",
    "                    line_count = sum(1 for _ in f)\n",
    "                \n",
    "                with open(file_path, 'r', encoding='gbk') as infile:\n",
    "                    file_lines = 0\n",
    "                    # 使用tqdm显示每个文件内部的处理进度\n",
    "                    for line in tqdm(infile, total=line_count, desc=f\"处理 {file_name} (GBK编码)\", leave=False):\n",
    "                        try:\n",
    "                            # 验证JSON格式是否正确\n",
    "                            json.loads(line.strip())\n",
    "                            outfile.write(line)\n",
    "                            file_lines += 1\n",
    "                        except json.JSONDecodeError:\n",
    "                            error_lines += 1\n",
    "                            continue\n",
    "                    \n",
    "                    total_lines += file_lines\n",
    "                    processed_files += 1\n",
    "                    print(f\"  - 已处理 {file_lines} 行 (GBK编码)\")\n",
    "            except Exception as e:\n",
    "                print(f\"  - 无法处理文件 {file_name}: {str(e)}\")\n",
    "\n",
    "print(\"\\n合并完成！\")\n",
    "print(f\"总共处理了 {processed_files} 个文件\")\n",
    "print(f\"合并了 {total_lines} 行数据\")\n",
    "print(f\"跳过了 {error_lines} 行无效数据\")\n",
    "print(f\"合并后的文件已保存为: {os.path.basename(output_file)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
